"In this article, we propose a new asymptotic equipartition property for the perplexity of a large piece of text in a large language model and present theoretical arguments for this property. We also present some experimental results from an open-source LLM that support our theoretical claims. Large language models are capable of producing grammatically correct natural language outputs that are long, detailed and information-rich from very short and simple user prompts. State-of-the-art LLMs are now able to produce text that can imitate human language well-enough to pass the Turing test i.e. resembles text created by humans well enough to be convincing to human observers. Perplexity is a popular metric for evaluating the performance of language models. It is also the statistical measure most commonly used by AI detection tools i.e. software to identify synthetic data created by generative models. Perplexity is closely related to the well-known information-theoretic concept of cross-entropy. Its use as a performance metric for training and evaluating language models is well-justified by standard results from information theory. However, there is little theoretical understanding of perplexity in its other role as a tool for detecting AI generated text. In this work, we address this gap by demonstrating an asymptotic relationship that must be satisfied by any large text produced by a language model."